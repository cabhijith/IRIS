{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from fastai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_classify = load_learner(Path('Fake-News'), 'final-6Ji.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports #\n",
    "from eventregistry import *\n",
    "from numpy.random import seed\n",
    "seed(0)\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Masking, Dense, concatenate, multiply, subtract, Dropout, Embedding, LSTM, GRU, Bidirectional, GlobalMaxPooling1D, Input, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from my_layers import SelfAttLayer, weightedAccCallback\n",
    "from score import score_submission, print_confusion_matrix, report_score\n",
    "\n",
    "abbr_list = [\"n't\",\"'d\",\"'ll\",\"'s\",\"'m\",\"'ve\",\"'re\"]\n",
    "\n",
    "\n",
    "def closest_word(originalWord, embeddings):\n",
    "    words = list(embeddings.keys())\n",
    "    currentClosest = words[0]\n",
    "    for word in words:\n",
    "        if jellyfish.jaro_winkler(originalWord, word) > jellyfish.jaro_winkler(originalWord, currentClosest):\n",
    "            currentClosest = word\n",
    "    print(\"Closest word to \" + originalWord +\" is \" + currentClosest)\n",
    "    return embeddings[currentClosest]\n",
    "\n",
    "def remove_parenthesis(sent):\n",
    "    return ' '.join(sent.replace('(', ' ').replace(')', ' ').replace('.', '').split()).lower()\n",
    "\n",
    "def clean(s):\n",
    "    # Cleans a string: Lowercasing, trimming, removing non-alphanumeric\n",
    "    return \" \".join(re.findall(r'\\w+', s, flags=re.UNICODE)).lower()\n",
    "def clean_fnc(s):\n",
    "    s = unidecode.unidecode(s) # for correct tokenization\n",
    "    tokens = word_tokenize(s)\n",
    "    for i, tok in enumerate(tokens):\n",
    "        if tok not in abbr_list:\n",
    "            tokens[i] = clean(tok)\n",
    "    return ' '.join(list(filter(lambda x: x != '', tokens))).lower()\n",
    "\n",
    "\n",
    "#/usr/bin/env python\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "# imports #\n",
    "from numpy.random import seed\n",
    "seed(0)\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Masking, Dense, concatenate, multiply, subtract, Dropout, Embedding, LSTM, GRU, Bidirectional, GlobalMaxPooling1D, Input, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from my_layers import SelfAttLayer, weightedAccCallback\n",
    "from score import score_submission, print_confusion_matrix, report_score\n",
    "\n",
    "# Some hyperparameters #\n",
    "hidden_units = 300\n",
    "max_seq_len = 50\n",
    "max_seqs = 30\n",
    "########################\n",
    "\n",
    "print(\"Opening features\")\n",
    "with open('Data_Fake/features.pkl', 'rb') as inpFeat:\n",
    "    overlapFeatures_fnc = pickle.load(inpFeat)\n",
    "    refutingFeatures_fnc = pickle.load(inpFeat)\n",
    "    polarityFeatures_fnc = pickle.load(inpFeat)\n",
    "    handFeatures_fnc = pickle.load(inpFeat)\n",
    "    overlapFeatures_fnc_test = pickle.load(inpFeat)\n",
    "    refutingFeatures_fnc_test = pickle.load(inpFeat)\n",
    "    polarityFeatures_fnc_test = pickle.load(inpFeat)\n",
    "    handFeatures_fnc_test = pickle.load(inpFeat)\n",
    "    overlapFeatures_nli = pickle.load(inpFeat)\n",
    "    refutingFeatures_nli = pickle.load(inpFeat)\n",
    "    polarityFeatures_nli = pickle.load(inpFeat)\n",
    "    handFeatures_nli = pickle.load(inpFeat)\n",
    "    overlapFeatures_nli_test = pickle.load(inpFeat)\n",
    "    refutingFeatures_nli_test = pickle.load(inpFeat)\n",
    "    polarityFeatures_nli_test = pickle.load(inpFeat)\n",
    "    handFeatures_nli_test = pickle.load(inpFeat)\n",
    "    overlapFeatures_matched_test = pickle.load(inpFeat)\n",
    "    refutingFeatures_matched_test = pickle.load(inpFeat)\n",
    "    polarityFeatures_matched_test = pickle.load(inpFeat)\n",
    "    handFeatures_matched_test = pickle.load(inpFeat)\n",
    "    overlapFeatures_mismatched_test = pickle.load(inpFeat)\n",
    "    refutingFeatures_mismatched_test = pickle.load(inpFeat)\n",
    "    polarityFeatures_mismatched_test = pickle.load(inpFeat)\n",
    "    handFeatures_mismatched_test = pickle.load(inpFeat)\n",
    "    overlapFeatures_fnc_two = pickle.load(inpFeat)\n",
    "    refutingFeatures_fnc_two = pickle.load(inpFeat)\n",
    "    polarityFeatures_fnc_two = pickle.load(inpFeat)\n",
    "    handFeatures_fnc_two = pickle.load(inpFeat)\n",
    "    overlapFeatures_fnc_two_test = pickle.load(inpFeat)\n",
    "    refutingFeatures_fnc_two_test = pickle.load(inpFeat)\n",
    "    polarityFeatures_fnc_two_test = pickle.load(inpFeat)\n",
    "    handFeatures_fnc_two_test = pickle.load(inpFeat)\n",
    "    bleu_nli = pickle.load(inpFeat)\n",
    "    bleu_nli_test = pickle.load(inpFeat)\n",
    "    bleu_matched = pickle.load(inpFeat)\n",
    "    bleu_mismatched = pickle.load(inpFeat)\n",
    "    rouge_nli = pickle.load(inpFeat)\n",
    "    rouge_nli_test = pickle.load(inpFeat)\n",
    "    rouge_matched = pickle.load(inpFeat)\n",
    "    rouge_mismatched = pickle.load(inpFeat)\n",
    "    bleu_fnc = pickle.load(inpFeat)\n",
    "    bleu_fnc_test = pickle.load(inpFeat)\n",
    "    bleu_two_sentences = pickle.load(inpFeat)\n",
    "    bleu_two_sentences_test = pickle.load(inpFeat)\n",
    "    rouge_fnc = pickle.load(inpFeat)\n",
    "    rouge_fnc_test = pickle.load(inpFeat)\n",
    "    rouge_two_sentences = pickle.load(inpFeat)\n",
    "    rouge_two_sentences_test = pickle.load(inpFeat)\n",
    "\n",
    "del overlapFeatures_nli, refutingFeatures_nli, polarityFeatures_nli, handFeatures_nli, overlapFeatures_nli_test , refutingFeatures_nli_test, \\\n",
    "    polarityFeatures_nli_test, handFeatures_nli_test, overlapFeatures_matched_test, refutingFeatures_matched_test, polarityFeatures_matched_test, \\\n",
    "    handFeatures_matched_test, overlapFeatures_mismatched_test, refutingFeatures_mismatched_test, polarityFeatures_mismatched_test, \\\n",
    "    handFeatures_mismatched_test, bleu_nli, bleu_nli_test, bleu_matched, bleu_mismatched, rouge_nli, rouge_nli_test, rouge_matched, rouge_mismatched\n",
    "\n",
    "print(\"Opening variables\")\n",
    "with open('Data_Fake/variables.pkl', 'rb') as inp:\n",
    "    embedding_weights = pickle.load(inp)\n",
    "    X1 = pickle.load(inp)\n",
    "    X2 = pickle.load(inp)\n",
    "    Y = pickle.load(inp)\n",
    "    X1_test = pickle.load(inp)\n",
    "    X2_test = pickle.load(inp)\n",
    "    Y_test = pickle.load(inp)\n",
    "    X1_nli = pickle.load(inp)\n",
    "    X2_nli = pickle.load(inp)\n",
    "    Y_nli = pickle.load(inp)\n",
    "    X1_test_nli = pickle.load(inp)\n",
    "    X2_test_nli = pickle.load(inp)\n",
    "    Y_test_nli = pickle.load(inp)\n",
    "    X1_test_matched = pickle.load(inp)\n",
    "    X2_test_matched = pickle.load(inp)\n",
    "    Y_test_matched = pickle.load(inp)\n",
    "    X1_test_mismatched = pickle.load(inp)\n",
    "    X2_test_mismatched = pickle.load(inp)\n",
    "    Y_test_mismatched = pickle.load(inp)\n",
    "    X2_two_sentences = pickle.load(inp)\n",
    "    X2_test_two_sentences = pickle.load(inp)\n",
    "    tokenizer = pickle.load(inp)\n",
    "\n",
    "    \n",
    "del X1_nli, X2_nli, Y_nli, X1_test_nli, X2_test_nli, Y_test_nli, X1_test_matched, X2_test_matched, Y_test_matched, X1_test_mismatched, \\\n",
    "    X2_test_mismatched, Y_test_mismatched\n",
    "\n",
    "print(\"Opening similarities\")\n",
    "with open('Data_Fake/similarity.pkl', 'rb') as inpSim:\n",
    "    cosFeatures = pickle.load(inpSim)\n",
    "    cosFeatures_test = pickle.load(inpSim)\n",
    "    cosFeatures_nli = pickle.load(inpSim)\n",
    "    cosFeatures_nli_test = pickle.load(inpSim)\n",
    "    cosFeatures_matched = pickle.load(inpSim)\n",
    "    cosFeatures_mismatched = pickle.load(inpSim)\n",
    "\n",
    "cosFeatures = np.array(cosFeatures)\n",
    "cosFeatures_test = np.array(cosFeatures_test)\n",
    "\n",
    "cosFeatures_fnc = []\n",
    "cosFeatures_two = []\n",
    "for feat in cosFeatures:\n",
    "    cosFeatures_fnc += [feat[0]]\n",
    "    cosFeatures_two += [feat[1]]\n",
    "cosFeatures_fnc = np.array(cosFeatures_fnc)\n",
    "cosFeatures_two = np.array(cosFeatures_two)\n",
    "\n",
    "cosFeatures_fnc_test = []\n",
    "cosFeatures_two_test = []\n",
    "for feat in cosFeatures_test:\n",
    "    cosFeatures_fnc_test += [feat[0]]\n",
    "    cosFeatures_two_test += [feat[1]]\n",
    "cosFeatures_fnc_test = np.array(cosFeatures_fnc_test)\n",
    "cosFeatures_two_test = np.array(cosFeatures_two_test)\n",
    "\n",
    "del cosFeatures_nli, cosFeatures_nli_test, cosFeatures_matched, cosFeatures_mismatched\n",
    "\n",
    "with open(\"Data_Fake/cider_fnc.pkl\", \"rb\") as ciderFile:\n",
    "    cider_fnc_train = pickle.load(ciderFile, encoding='latin1')\n",
    "    cider_fnc_test = pickle.load(ciderFile, encoding='latin1')\n",
    "    cider_two_train = pickle.load(ciderFile, encoding='latin1')\n",
    "    cider_two_test = pickle.load(ciderFile, encoding='latin1')\n",
    "\n",
    "import pickle as cPickle\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/train.basic.pkl\", \"rb\") as countsTrain:\n",
    "    names = cPickle.load(countsTrain)\n",
    "    talos_counts_train = cPickle.load(countsTrain, encoding='latin1')\n",
    "print('Done')\n",
    "with open(\"talos-fnc-1-py3/tree_model/test.basic.pkl\", \"rb\") as countsTest:\n",
    "    names = cPickle.load(countsTest)\n",
    "    talos_counts_test = cPickle.load(countsTest, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/train.sim.tfidf.pkl\", \"rb\") as tfidfSim_train:\n",
    "    talos_tfidfsim_train = cPickle.load(tfidfSim_train, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/test.sim.tfidf.pkl\", \"rb\") as tfidfSim_test:\n",
    "    talos_tfidfsim_test = cPickle.load(tfidfSim_test, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/train.headline.svd.pkl\", \"rb\") as svdHealine_train:\n",
    "    talos_svdHeadline_train = cPickle.load(svdHealine_train, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/test.headline.svd.pkl\", \"rb\") as svdHealine_test:\n",
    "    talos_svdHeadline_test = cPickle.load(svdHealine_test, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/train.body.svd.pkl\", \"rb\") as svdBody_train:\n",
    "    talos_svdBody_train = cPickle.load(svdBody_train, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/test.body.svd.pkl\", \"rb\") as svdBody_test:\n",
    "    talos_svdBody_test = cPickle.load(svdBody_test, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/train.sim.svd.pkl\", \"rb\") as svdSim_train:\n",
    "    talos_svdsim_train = cPickle.load(svdSim_train, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/test.sim.svd.pkl\", \"rb\") as svdSim_test:\n",
    "    talos_svdsim_test = cPickle.load(svdSim_test, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/train.headline.word2vec.pkl\", \"rb\") as w2vHealine_train:\n",
    "    talos_w2vHeadline_train = cPickle.load(w2vHealine_train, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/test.headline.word2vec.pkl\", \"rb\") as w2vHealine_test:\n",
    "    talos_w2vHeadline_test = cPickle.load(w2vHealine_test, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/train.body.word2vec.pkl\", \"rb\") as w2vBody_train:\n",
    "    talos_w2vBody_train = cPickle.load(w2vBody_train, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/test.body.word2vec.pkl\", \"rb\") as w2vBody_test:\n",
    "    talos_w2vBody_test = cPickle.load(w2vBody_test, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/train.sim.word2vec.pkl\", \"rb\") as w2vSim_train:\n",
    "    talos_w2vsim_train = cPickle.load(w2vSim_train, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/test.sim.word2vec.pkl\", \"rb\") as w2vSim_test:\n",
    "    talos_w2vsim_test = cPickle.load(w2vSim_test, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/train.headline.senti.pkl\", \"rb\") as sentiHealine_train:\n",
    "    talos_sentiHeadline_train = cPickle.load(sentiHealine_train, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/test.headline.senti.pkl\", \"rb\") as sentiHealine_test:\n",
    "    talos_sentiHeadline_test = cPickle.load(sentiHealine_test, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/train.body.senti.pkl\", \"rb\") as sentiBody_train:\n",
    "    talos_sentiBody_train = cPickle.load(sentiBody_train, encoding='latin1')\n",
    "\n",
    "with open(\"talos-fnc-1-py3/tree_model/test.body.senti.pkl\", \"rb\") as sentiBody_test:\n",
    "    talos_sentiBody_test = cPickle.load(sentiBody_test, encoding='latin1')\n",
    "\n",
    "########################## Definir o modelo ##################################### \n",
    "\n",
    "#Define some model layers #\n",
    "print('Done ! Done ! Done !')\n",
    "early_stop = EarlyStopping(monitor='loss', patience=2, verbose=1, restore_best_weights=True)\n",
    "weightedAccuracy = weightedAccCallback(X1_test, X2_test, Y_test, overlapFeatures_fnc_test, refutingFeatures_fnc_test, polarityFeatures_fnc_test, handFeatures_fnc_test,  \\\n",
    "                                       cosFeatures_fnc_test,cosFeatures_two_test, bleu_fnc_test, rouge_fnc_test,cider_fnc_test, X2_test_two_sentences, overlapFeatures_fnc_two_test, \\\n",
    "                                       refutingFeatures_fnc_two_test, polarityFeatures_fnc_two_test, handFeatures_fnc_two_test, \\\n",
    "                                       bleu_two_sentences_test, rouge_two_sentences_test, cider_two_test\n",
    "                                       , talos_counts_test, talos_tfidfsim_test, talos_svdHeadline_test, \\\n",
    "                                       talos_svdBody_test, talos_svdsim_test,talos_w2vHeadline_test, talos_w2vBody_test, talos_w2vsim_test, talos_sentiHeadline_test, talos_sentiBody_test)\n",
    "                                     \n",
    "\n",
    "embedding_layer = Embedding( embedding_weights.shape[0], embedding_weights.shape[1], input_length=max_seq_len, weights=[embedding_weights], trainable=False )\n",
    "lstm1 = LSTM(hidden_units, implementation=2, return_sequences=True, name='lstm1' )\n",
    "lstm1 = Bidirectional(lstm1, name='bilstm1')\n",
    "right_branch_lstm1 = LSTM(hidden_units, implementation=2, return_sequences=True )\n",
    "right_branch_lstm1 = Bidirectional(right_branch_lstm1)\n",
    "\n",
    "#####################################\n",
    "\n",
    "# Define the inputs for the model #\n",
    "\n",
    "input_headline = Input(shape=(max_seq_len,))\n",
    "input_two = Input(shape=(max_seq_len,))\n",
    "input_body = Input(shape=(max_seqs, max_seq_len,))\n",
    "input_overlap = Input(shape=(1,))\n",
    "input_overlap_two = Input(shape=(1,))\n",
    "input_refuting = Input(shape=(15,))\n",
    "input_refuting_two = Input(shape=(15,))\n",
    "input_polarity = Input(shape=(2,))\n",
    "input_polarity_two = Input(shape=(2,))\n",
    "input_hand = Input(shape=(26,))\n",
    "input_hand_two = Input(shape=(26,))\n",
    "input_sim = Input(shape=(1,))\n",
    "input_sim_two = Input(shape=(1,))\n",
    "input_bleu = Input(shape=(1,))\n",
    "input_bleu_two = Input(shape=(1,))\n",
    "input_rouge = Input(shape=(3,))\n",
    "input_rouge_two = Input(shape=(3,))\n",
    "input_cider = Input(shape=(1,))\n",
    "input_cider_two = Input(shape=(1,))\n",
    "\n",
    "input_talos_count = Input(shape=(41,))\n",
    "input_talos_tfidfsim = Input(shape=(1,))\n",
    "input_talos_headline_svd = Input(shape=(50,))\n",
    "input_talos_body_svd = Input(shape=(50,))\n",
    "input_talos_svdsim = Input(shape=(1,))\n",
    "input_talos_headline_w2v = Input(shape=(300,))\n",
    "input_talos_body_w2v = Input(shape=(300,))\n",
    "input_talos_w2vsim = Input(shape=(1,))\n",
    "input_talos_headline_senti = Input(shape=(4,))\n",
    "input_talos_body_senti = Input(shape=(4,))\n",
    "\n",
    "\n",
    "###############################\n",
    "\n",
    "# Define the sentence encoder #\n",
    "\n",
    "mask = Masking(mask_value=0, input_shape=(max_seq_len,))(input_headline)\n",
    "embed = embedding_layer(mask)\n",
    "l1 = lstm1(embed)\n",
    "drop1 = Dropout(0.1)(l1)\n",
    "maxim = GlobalMaxPooling1D()(drop1)\n",
    "att = SelfAttLayer(name='attention')(drop1)\n",
    "out = concatenate([maxim, att])\n",
    "HeadlineEncoder = Model(input_headline, maxim, name='HeadlineEncoder')\n",
    "\n",
    "# HeadlineEncoder.set_weights(layer_dict['SentenceEncoder'].get_weights())\n",
    "\n",
    "##############################\n",
    "\n",
    "# Define the document encoder #\n",
    "\n",
    "body_sentence = TimeDistributed(HeadlineEncoder)(input_body)\n",
    "body_g1 = right_branch_lstm1(body_sentence)\n",
    "body_g1 = Dropout(0.1)(body_g1)\n",
    "body_maxim = GlobalMaxPooling1D()(body_g1)\n",
    "body_att = SelfAttLayer()(body_g1)\n",
    "body_out = concatenate([body_maxim, body_att])\n",
    "DocumentEncoder = Model(input_body, body_maxim, name='DocumentEncoder')\n",
    "\n",
    "##############################\n",
    "\n",
    "# Combining both representations #\n",
    "\n",
    "headline_representation = HeadlineEncoder(input_headline)\n",
    "document_representation = DocumentEncoder(input_body)\n",
    "\n",
    "# Match between headline and first two sentences from body #\n",
    "\n",
    "two_sentences_representation = HeadlineEncoder(input_two)\n",
    "concat_two = concatenate([headline_representation, two_sentences_representation])\n",
    "mul_two = multiply([headline_representation, two_sentences_representation])\n",
    "dif_two = subtract([headline_representation, two_sentences_representation])\n",
    "final_merge_two = concatenate([concat_two, mul_two, dif_two, input_overlap_two, input_refuting_two, input_polarity_two, input_hand_two, \\\n",
    "                               input_sim_two, input_bleu_two, input_rouge_two, input_cider_two])\n",
    "drop3_two = Dropout(0.1)(final_merge_two)\n",
    "dense1_two = Dense(hidden_units*2, activation='relu')(drop3_two)\n",
    "# , weights=layer_dict['dense1'].get_weights()\n",
    "drop4_two = Dropout(0.1)(dense1_two)\n",
    "dense2_two = Dense(hidden_units, activation='relu')(drop4_two)\n",
    "# ,weights=layer_dict['dense2'].get_weights()\n",
    "match = Dropout(0.1)(dense2_two)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "concat = concatenate([headline_representation, document_representation])\n",
    "mul = multiply([headline_representation, document_representation])\n",
    "dif = subtract([headline_representation, document_representation])\n",
    "final_merge = concatenate([concat, mul, dif, input_overlap, input_refuting, input_polarity, input_hand, input_sim, input_bleu, input_rouge, input_cider])\n",
    "drop3 = Dropout(0.1)(final_merge)\n",
    "dense1 = Dense(hidden_units*2, activation='relu', name='dense1')(drop3)\n",
    "# , weights=layer_dict['dense1'].get_weights()\n",
    "drop4 = Dropout(0.1)(dense1)\n",
    "dense2 = Dense(hidden_units, activation='relu', name='dense2')(drop4)\n",
    "# , weights=layer_dict['dense2'].get_weights()\n",
    "drop5 = Dropout(0.1)(dense2)\n",
    "concat_final = concatenate([drop5,match,input_talos_count, input_talos_tfidfsim, input_talos_headline_svd, input_talos_body_svd, \\\n",
    "                     input_talos_svdsim, input_talos_headline_w2v, input_talos_body_w2v, input_talos_w2vsim, \\\n",
    "                     input_talos_headline_senti, input_talos_body_senti])\n",
    "drop6 = Dropout(0.1)(concat_final)\n",
    "dense3 = Dense(4, activation='softmax')(drop6)\n",
    "final_model = Model([input_headline, input_body,input_overlap, input_refuting, input_polarity, input_hand, \\\n",
    "                     input_sim, input_sim_two, input_bleu, input_rouge,input_cider, input_two, input_overlap_two, input_refuting_two, input_polarity_two, input_hand_two, \\\n",
    "                     input_bleu_two, input_rouge_two, input_cider_two, input_talos_count, input_talos_tfidfsim, input_talos_headline_svd, input_talos_body_svd, \\\n",
    "                     input_talos_svdsim, input_talos_headline_w2v, input_talos_body_w2v, input_talos_w2vsim, \\\n",
    "                     input_talos_headline_senti, input_talos_body_senti], dense3)\n",
    "#######################################################################################\n",
    "\n",
    "final_model.summary()\n",
    "\n",
    "final_model.compile(optimizer=Adam(amsgrad=True), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(keyss):\n",
    "  print(len(keyss), 'keywords were found in total')\n",
    "\n",
    "def articles_found(all_articles):\n",
    "    print(len(all_articles), 'articles were retreived')\n",
    "\n",
    "\n",
    "def compute_features():\n",
    "  print('Computing features completed')\n",
    "\n",
    "def make_predictions(keyss, all_body, head, all_articles, test_predictions):\n",
    "  get_keywords(keyss)\n",
    "  sleep(2)\n",
    "  print('-' * 100)\n",
    "  articles_found(all_articles)\n",
    "  sleep(2)\n",
    "  final_output(all_body, keyss, head, test_predictions)\n",
    "  print('-' * 100)\n",
    "\n",
    "\n",
    "def final_output(all_body, keyss, head, test_predictions): \n",
    "      ling = learn_classify.predict(head)\n",
    "      hh = ling[2][0]\n",
    "      hhh = ling[2][1] #Second Accuracy \n",
    "\n",
    "\n",
    "      if len(all_articles) > 15 and len(keyss) > 1:\n",
    "            score(test_predictions)\n",
    "            \n",
    "      elif hh > hhh:\n",
    "        print('')\n",
    "        print('The prediction is FAKE. The model has a confidence of ', hh)\n",
    "\n",
    "      else:\n",
    "          print('The prediction is REAL. The model has a confidence of ', hhh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = \"\"\"\"Pay Rs. 2000 and get the best relationship advice ever. Over 2,00,000 marraiges saved this way. What are you waiting for? \n",
    "           Sve your marriage now, sign up with the link below\"\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_headline(head):\n",
    "\n",
    "    paralleldots.set_api_key(\"fsnXrEyuNaaj2GIHdrEgo0voVRlAwUMWPd2mahaxZPQ\")\n",
    "    response=paralleldots.phrase_extractor(text_head)\n",
    "    a1 = response['keywords']\n",
    "    highest_score = 0\n",
    "    keyword_head=[]\n",
    "    for i in a1:\n",
    "          if i['relevance_score'] == highest_score:\n",
    "            keyword_head.append(i['keyword'])\n",
    "            highest_score = i['relevance_score']\n",
    "          if i['relevance_score'] > highest_score:\n",
    "            keyword_head = []\n",
    "            keyword_head.append(i['keyword'])\n",
    "            highest_score = i['relevance_score']\n",
    "          else:\n",
    "            continue \n",
    "    return(keyword_head)\n",
    "keyss = get_keywords_headline()\n",
    "\n",
    "def get_keywords_body(text_body):\n",
    "   paralleldots.set_api_key(\"fsnXrEyuNaaj2GIHdrEgo0voVRlAwUMWPd2mahaxZPQ\")\n",
    "   response=paralleldots.batch_phrase_extractor(text_body)\n",
    "   a1 = response['phrases']\n",
    "   a2 = a1[0] #Doing this in non-pythonic way because of weird structure of the data \n",
    "   highest_score = 0\n",
    "   keyword_body = []\n",
    "   for i in a2:\n",
    "      if i['relevance_score'] == highest_score:\n",
    "        keyword_body.append(i['keyword'])\n",
    "        highest_score = i['relevance_score']\n",
    "      if i['relevance_score'] > highest_score:\n",
    "        keyword_body = []\n",
    "        keyword_body.append(i['keyword'])\n",
    "        highest_score = i['relevance_score']\n",
    "      else:\n",
    "        continue \n",
    "   return(keyword_body)\n",
    "\n",
    "keys_body = get_keywords_body()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(keyss):\n",
    "  er = EventRegistry(apiKey = 'd22a09b4-80de-4689-9134-e0118c30ada3')\n",
    "  q = QueryArticlesIter(\n",
    "      keywords = QueryItems.AND(keyss),\n",
    "   dataType   = [\"news\", \"blog\"],\n",
    "       lang = 'eng',\n",
    "       startSourceRankPercentile = 0,\n",
    "      endSourceRankPercentile = 30)\n",
    "  # obtain at most 500 newest articles or blog posts\n",
    "  all_data=[]\n",
    "  for art in q.execQuery(er, sortBy = \"relevancy\", maxItems = 10):\n",
    "      all_data.append(art)\n",
    "  return(all_data)\n",
    "\n",
    "all_articles = get_articles(keyss)\n",
    "len(all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_body = []\n",
    "for i in all_articles:\n",
    "  all_body.append(i['body'])\n",
    "\n",
    "all_head = []\n",
    "for i in range(0,len(all_body)):\n",
    "  all_head.append(head)\n",
    "all_articles.append('Placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_head = all_head\n",
    "X2_body = all_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engineering import polarity_features, refuting_features, word_overlap_features, hand_features\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import unidecode\n",
    "from keras.preprocessing import sequence\n",
    "import re\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "overlapFeatures_fnc_test = np.array(word_overlap_features(X1_head, X2_body))\n",
    "refutingFeatures_fnc_test = np.array(refuting_features(X1_head, X2_body))\n",
    "polarityFeatures_fnc_test = np.array(polarity_features(X1_head, X2_body))\n",
    "handFeatures_fnc_test = np.array(hand_features(X1_head, X2_body))\n",
    "\n",
    "bleu_fnc_test = []\n",
    "for i in range(len(X1_head)):\n",
    "    split_doc = sent_tokenize(X1_head[i])\n",
    "    for j in range(len(split_doc)):\n",
    "        split_doc[j] = word_tokenize(clean_fnc(split_doc[j]))\n",
    "    bleu_fnc_test += [ sentence_bleu(split_doc, word_tokenize(X1_head[i]) ) ]\n",
    "bleu_fnc_test = np.array(bleu_fnc_test)\n",
    "\n",
    "rouge_fnc_test = []\n",
    "fails = 0\n",
    "for i in range(len(X1_head)):\n",
    "    rouge_values = []\n",
    "    try:\n",
    "        scores = rouge.get_scores(clean(X2_test[i]), clean(X1_head[i]))\n",
    "        rouge_values += [scores[0]['rouge-1']['f']]\n",
    "        rouge_values += [scores[0]['rouge-2']['f']]\n",
    "        rouge_values += [scores[0]['rouge-l']['f']]\n",
    "    except:\n",
    "        fails += 1\n",
    "        rouge_values = [0,0,0]\n",
    "    rouge_fnc_test += [rouge_values]\n",
    "print(\"ROUGE FNC TEST: {} fails\".format(fails))\n",
    "rouge_fnc_test = np.array(rouge_fnc_test)\n",
    "\n",
    "X2_test_two_sentences = []\n",
    "for document in X2_body:\n",
    "    sentences = sent_tokenize(document)\n",
    "    try:\n",
    "        X2_test_two_sentences += ['| ' + clean_fnc(sentences[0]) + ' ' + clean_fnc(sentences[1]) + ' |']\n",
    "    except:\n",
    "        X2_test_two_sentences += ['| ' + clean_fnc(sentences[0]) + ' |']\n",
    "  \n",
    "\n",
    "overlapFeatures_fnc_two_test = np.array(word_overlap_features(X1_head, X2_test_two_sentences))\n",
    "refutingFeatures_fnc_two_test = np.array(refuting_features(X1_head, X2_test_two_sentences))\n",
    "polarityFeatures_fnc_two_test = np.array(polarity_features(X1_head, X2_test_two_sentences))\n",
    "handFeatures_fnc_two_test = np.array(hand_features(X1_head, X2_test_two_sentences))\n",
    "\n",
    "\n",
    "bleu_two_sentences_test = []\n",
    "for i in range(len(X1_head)):\n",
    "    bleu_two_sentences_test += [ sentence_bleu(word_tokenize(clean_fnc(X2_test_two_sentences[i])), \\\n",
    "                                          word_tokenize(X1_head[i]) ) ]\n",
    "bleu_two_sentences_test = np.array(bleu_two_sentences_test)\n",
    "\n",
    "\n",
    "\n",
    "rouge_two_sentences_test = []\n",
    "for i in range(len(X1_head)):\n",
    "    rouge_values = []\n",
    "    scores = rouge.get_scores(clean(X2_test_two_sentences[i]), clean(X1_head[i]))\n",
    "    rouge_values += [scores[0]['rouge-1']['f']]\n",
    "    rouge_values += [scores[0]['rouge-2']['f']]\n",
    "    rouge_values += [scores[0]['rouge-l']['f']]\n",
    "    rouge_two_sentences_test += [rouge_values]\n",
    "rouge_two_sentences_test = np.array(rouge_two_sentences_test)\n",
    "\n",
    "X2_test_two_sentences = sequence.pad_sequences( tokenizer.texts_to_sequences( X2_test_two_sentences ) , maxlen=max_seq_len )\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_head = sequence.pad_sequences( tokenizer.texts_to_sequences( X1_head) , maxlen=max_seq_len ) # Mesma coisa para headlines de teste\n",
    "X1_head = np.asarray(X1_head)\n",
    "\n",
    "data_aux = np.zeros( ( len(X2_body) , max_seqs , max_seq_len ) ) # len(X2) = numero total de bodies do dataset, max_seq_len = 30, max_seqs = 15\n",
    "for i, sentences in enumerate(X2_body):\n",
    "    sentences = sent_tokenize( sentences )\n",
    "    sentences = list(map(lambda x: '| ' + clean_fnc(x) + ' |', sentences))\n",
    "    aux = [ ]\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j < max_seqs: data_aux[i,j] = sequence.pad_sequences( tokenizer.texts_to_sequences( [ sent ] ) , maxlen=max_seq_len )[0]\n",
    "X2_body = np.asarray(data_aux)\n",
    "\n",
    "# final_model.load_weights(\"fnc-weights.h5\")\n",
    "# final_model1 = load_model(\"fnc-weights-save.h5\")\n",
    "\n",
    "test_outputs = []\n",
    "test_predictions = []\n",
    "labels = ['unrelated', 'agree', 'disagree', 'discuss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = final_model1.predict([X1_head, \n",
    "                                  X2_body, overlapFeatures_fnc_test, refutingFeatures_fnc_test, polarityFeatures_fnc_test, handFeatures_fnc_test,  \\\n",
    "                                  cosFeatures_fnc_test, cosFeatures_two_test, bleu_fnc_test, rouge_fnc_test, cider_fnc_test, \\\n",
    "                                  X2_test_two_sentences, overlapFeatures_fnc_two_test, refutingFeatures_fnc_two_test, polarityFeatures_fnc_two_test, handFeatures_fnc_two_test, \\\n",
    "                                  bleu_two_sentences_test, rouge_two_sentences_test, cider_two_test, talos_counts_test, talos_tfidfsim_test, talos_svdHeadline_test, talos_svdBody_test, talos_svdsim_test, \\\n",
    "                                  talos_w2vHeadline_test, \n",
    "                               talos_w2vBody_test, \n",
    "                           talos_w2vsim_test, \n",
    "                           talos_sentiHeadline_test, \n",
    "                           talos_sentiBody_test])\n",
    "# aux = final_model1.predict([X1_head, X2_body])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "preds = []\n",
    "for prediction in aux:\n",
    "    pred = prediction.argmax()\n",
    "    if pred == 0:\n",
    "        one_hot = [1,0,0,0]\n",
    "    if pred == 1:\n",
    "        one_hot = [0,1,0,0]\n",
    "    if pred == 2:\n",
    "        one_hot = [0,0,1,0]\n",
    "    if pred == 3:\n",
    "        one_hot = [0,0,0,1]\n",
    "    preds += [one_hot]\n",
    "    test_predictions += [labels[prediction.argmax()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(test_predictions):\n",
    "  score = 0\n",
    "  count = 0 \n",
    "  for i in test_predictions:\n",
    "    if i == 'agree':\n",
    "      score += 1\n",
    "      \n",
    "    if i == 'disagree':\n",
    "      score-= 2\n",
    "    if i == 'discuss':\n",
    "      score -= 0\n",
    "       \n",
    "    count +=1\n",
    "  if score > 0:\n",
    "      print('The text is REAL. The model has a confidence of ', score/len(all_articles) * 100, ' %' )\n",
    "  else:\n",
    "       print('The text is FAKE. The model has a confidence of ', score/len(all_articles) * 100, '%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions( keyss, all_body, head, all_articles, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
